{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f35019-786b-4542-b816-de18a6fd13d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/whisperx/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import whisperx\n",
    "import gc \n",
    "import torch\n",
    "import freetype\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "import subprocess as sp\n",
    "import gradio as gr\n",
    "from utils.configservice import CONFIG_DICT\n",
    "from moviepy.editor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbfe0ce4-9065-40fc-8c46-db4677b17954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordinfo_arr(title, st, et, total_chr):\n",
    "    arr = [title]\n",
    "    new_word_arr = []\n",
    "    new_start_time_arr = []\n",
    "    new_end_time_arr = []\n",
    "    i = 0\n",
    "    while(i < len(arr)):\n",
    "        if len(arr[i]) > total_chr :\n",
    "            word = arr[i][0 : total_chr-1] + '-'      #add - with remaining word\n",
    "            new_word_arr.append(word)\n",
    "            arr[i] = arr[i][total_chr-1::]\n",
    "        else:\n",
    "            new_word_arr.append(arr[i])\n",
    "            i += 1\n",
    "            \n",
    "    duration  = (et-st)/len(new_word_arr)\n",
    "    start = st\n",
    "    \n",
    "    for i in new_word_arr:\n",
    "        \n",
    "        new_start_time_arr.append(start)\n",
    "        new_end_time_arr.append(start + duration)\n",
    "        \n",
    "        start += duration  \n",
    "        \n",
    "    return new_word_arr, new_start_time_arr,  new_end_time_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1c2f5f-918a-4b8b-9a3c-b7d67e1bc872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_clip(text, color, font_ttf_path, font_size = 45, start = 0, end = 2, x_pos = 0, y_pos = 0):\n",
    "    stroke_width = font_size/50\n",
    "    clip = TextClip(text, color = color, fontsize = font_size, font = font_ttf_path, stroke_width = stroke_width,\n",
    "                    stroke_color = \"black\")\n",
    "    clip = clip.set_position((x_pos, y_pos))\n",
    "    clip = clip.set_start(start)\n",
    "    clip = clip.set_end(end)\n",
    "    return clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4d5a8ac-13f0-4bc8-b090-74ea61161b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_width(title, font_size, font_ttf_path):\n",
    "    max_width = 0\n",
    "    max_height = 0\n",
    "    for i in title:\n",
    "        if i == ' ':\n",
    "            continue\n",
    "        character = i\n",
    "        font_ttf_path = font_ttf_path\n",
    "        font = freetype.Face(font_ttf_path)\n",
    "        font.set_char_size(int(font_size * 64))\n",
    "        font.load_char(character)\n",
    "        width = font.glyph.bitmap.width\n",
    "        height = font.glyph.bitmap.rows\n",
    "        max_width = max(max_width,width)\n",
    "        max_height = max(max_height,height)\n",
    "    return max_width, max_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b2ace38-6c93-4ca2-bdf7-0a847b989244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_formation(Str, video, new_word_arr, new_start_time_arr, new_end_time_arr, text_index_arr, clip_arr, \n",
    "                   highlight_clip_arr, color_clip_arr, font_ttf_path, font_size, width_of_chr, height_of_chr, rgb_highlight_color):\n",
    "    video_w = video.size[0]\n",
    "    y_pos =  video.size[1] * 0.75\n",
    "    text_clip_test = create_text_clip(Str, \"white\", font_ttf_path, font_size)\n",
    "    start_x_pos = (video_w - text_clip_test.size[0]) / 2\n",
    "    x_pos = start_x_pos\n",
    "\n",
    "    start_time_index = text_index_arr[0]\n",
    "    end_time_index = text_index_arr[-1]\n",
    "\n",
    "    start_time = new_start_time_arr[start_time_index]\n",
    "    end_time = new_end_time_arr[end_time_index]\n",
    "\n",
    "    for j in range(0, len(text_index_arr)):\n",
    "        if j == len(text_index_arr)-1:\n",
    "            clip_word = new_word_arr[text_index_arr[j]]\n",
    "        else:\n",
    "            clip_word = new_word_arr[text_index_arr[j]] + \" \"\n",
    "\n",
    "        clip = create_text_clip(clip_word, \"white\", font_ttf_path, font_size, start_time, end_time, x_pos, y_pos)\n",
    "        clip_w, clip_h = clip.size\n",
    "\n",
    "        shadow_shift_x = 1.4 * (width_of_chr / 9) \n",
    "        shadow_shift_y = 1.5 * (height_of_chr / 10)\n",
    "        shadow_x_pos =  x_pos + shadow_shift_x\n",
    "        shadow_y_pos = y_pos + shadow_shift_y\n",
    "        shadow_clip = create_text_clip(clip_word, \"black\", font_ttf_path, font_size, start_time, end_time, shadow_x_pos, shadow_y_pos)\n",
    "       \n",
    "        clip_word_start = new_start_time_arr[text_index_arr[j]]\n",
    "        clip_word_end = new_end_time_arr[text_index_arr[j]]\n",
    "\n",
    "        highlight_clip = create_text_clip(clip_word, rgb_highlight_color, font_ttf_path, font_size, clip_word_start, clip_word_end, x_pos, y_pos)\n",
    "        \n",
    "        \n",
    "        \n",
    "        color_clip = ColorClip(size = (clip_w + int(clip_w * 0.01), clip_h - int(clip_h * 0.01)), color = (60, 60, 60))\n",
    "        color_clip = color_clip.set_start(clip_word_start)\n",
    "        color_clip = color_clip.set_end(clip_word_end)\n",
    "        color_clip = color_clip.set_position((x_pos, y_pos))\n",
    "        color_clip = color_clip.set_opacity(0.3)\n",
    "        \n",
    "\n",
    "        x_pos += clip_w\n",
    "\n",
    "        color_clip_arr.append(color_clip)\n",
    "        clip_arr.append(shadow_clip)\n",
    "        clip_arr.append(clip)\n",
    "        highlight_clip_arr.append(highlight_clip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fec689a9-3612-4dbf-8c74-bfdd5ebc710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_formation(new_word_arr, new_start_time_arr, new_end_time_arr, total_chr, video, width_of_chr, \n",
    "                       height_of_chr, font_ttf_path):\n",
    "    \n",
    "    rgb_color_arr = CONFIG_DICT[\"RGB_COLOR_ARR\"]\n",
    "    rgb_highlight_color = random.choice(rgb_color_arr)\n",
    "    \n",
    "    video_w = video.size[0]\n",
    "    y_pos =  video.size[1]*0.75\n",
    "    total_size = 0\n",
    "    Str = \"\"\n",
    "    text_index_arr = []\n",
    "    font_size = 50\n",
    "    clip_arr = []\n",
    "    highlight_clip_arr = []\n",
    "    color_clip_arr = []\n",
    "    \n",
    "    for i in range(0, len(new_word_arr)):\n",
    "        word = new_word_arr[i]\n",
    "        if total_size + len(word) + 1 < total_chr:\n",
    "            Str += word + \" \"  \n",
    "            text_index_arr.append(i)\n",
    "            total_size += len(word) + 1\n",
    "                            \n",
    "        elif total_size + len(word) + 1 == total_chr:\n",
    "            Str += word\n",
    "            text_index_arr.append(i)\n",
    "            total_size += len(word)\n",
    "            \n",
    "        else:  \n",
    "            \n",
    "            clip_formation(Str, video, new_word_arr, new_start_time_arr, new_end_time_arr, text_index_arr, clip_arr, \n",
    "                           highlight_clip_arr, color_clip_arr, font_ttf_path, font_size, width_of_chr, height_of_chr, rgb_highlight_color)\n",
    "                \n",
    "            Str = word\n",
    "            total_size = len(word)\n",
    "            text_index_arr = [i]\n",
    "            \n",
    "    clip_formation(Str, video, new_word_arr, new_start_time_arr, new_end_time_arr, text_index_arr, clip_arr,\n",
    "                   highlight_clip_arr, color_clip_arr, font_ttf_path, font_size, width_of_chr, height_of_chr, rgb_highlight_color)\n",
    "\n",
    "\n",
    "\n",
    "    return clip_arr, highlight_clip_arr, color_clip_arr \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cba323a-3464-4692-bb90-d2e14cae6e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_audio(url, audio_file):\n",
    "    \"\"\"\n",
    "    download files for processing\n",
    "    -----\n",
    "    Arguments\n",
    "    url: String - url of file\n",
    "    -----\n",
    "    Returns\n",
    "    None: mp4 and mp3 variants to save\n",
    "    \"\"\"\n",
    "    sp.call(f\"wget {url} -O ./{audio_file}\", shell = True, stdout = sp.DEVNULL, stderr = sp.DEVNULL)\n",
    "    print(f'audio saved at {audio_file} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "036426f1-b2a3-46f0-af41-74d592681878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_total_character_one_frame(TITLE, font_size, font_ttf_path, video_w):\n",
    "    width_of_chr, height_of_chr = find_max_width(TITLE, font_size, font_ttf_path)\n",
    "    x_margin = video_w * 0.98\n",
    "    total_chr_one_line = math.ceil((x_margin) / width_of_chr)\n",
    "    return width_of_chr, height_of_chr, total_chr_one_line\n",
    "          \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1018c930-fa36-4eb8-814c-56945a91efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_word_and_timestamps(segments):\n",
    "    start_time_arr = []\n",
    "    end_time_arr = []\n",
    "    word_arr = []\n",
    "    count = 0\n",
    "\n",
    "    for segment in segments:\n",
    "        for word_data in segment[\"words\"]:\n",
    "            if(len(word_data)) < 3:\n",
    "                if count != 0:\n",
    "                    print(start_time_arr[-1], end_time_arr[-1])\n",
    "                    half_duration = (end_time_arr[-1] - start_time_arr[-1]) / 2\n",
    "\n",
    "                    end_time_arr[-1] -= half_duration\n",
    "                    print(start_time_arr[-1], end_time_arr[-1])\n",
    "                    word = word_data[\"word\"]\n",
    "                    st = end_time_arr[-1]\n",
    "                    et = st + half_duration\n",
    "\n",
    "                    start_time_arr.append(st)\n",
    "                    end_time_arr.append(et)\n",
    "                    word_arr.append(word)\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                word = word_data[\"word\"]\n",
    "                st = word_data[\"start\"]\n",
    "                et = word_data[\"end\"]\n",
    "                start_time_arr.append(st)\n",
    "                end_time_arr.append(et)\n",
    "                word_arr.append(word)\n",
    "                count += 1\n",
    "            \n",
    "    return start_time_arr, end_time_arr, word_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30515782-2742-40aa-95c2-6b8e11d1be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_fit_one_line(start_time_arr, end_time_arr, word_arr, total_chr_one_line):\n",
    "    new_start_time_arr = []\n",
    "    new_end_time_arr = []\n",
    "    new_word_arr = []\n",
    "    for i in range(0, len(word_arr)):\n",
    "        word = word_arr[i]\n",
    "        st = start_time_arr[i]\n",
    "        et = end_time_arr[i]\n",
    "        a, b, c = create_wordinfo_arr(word, st, et, total_chr_one_line)\n",
    "        new_word_arr += a\n",
    "        new_start_time_arr += b\n",
    "        new_end_time_arr += c\n",
    "    return new_start_time_arr, new_end_time_arr, new_word_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b652f195-9433-4010-a5e7-2be371f4b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_the_generated_data(segments, total_chr_one_line):\n",
    "    start_time_arr, end_time_arr, word_arr = extract_word_and_timestamps(segments)\n",
    "    new_start_time_arr, new_end_time_arr, new_word_arr = word_fit_one_line(start_time_arr, end_time_arr, word_arr, total_chr_one_line)\n",
    "    return new_start_time_arr, new_end_time_arr, new_word_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b47e73e-b252-4e2f-b4b8-bbab58a1dcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(audio_file):\n",
    "    device = CONFIG_DICT[\"DEVICE\"]\n",
    "    batch_size = CONFIG_DICT[\"BATCH_SIZE\"]  # reduce if low on GPU mem\n",
    "    compute_type = CONFIG_DICT[\"COMPUTE_TYPE\"]  # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "    size = CONFIG_DICT[\"WHISPER_MODEL_TYPE\"]\n",
    "    language = CONFIG_DICT[\"LANGUAGE\"]\n",
    "\n",
    "    model = whisperx.load_model(size, device, compute_type = compute_type,language = language)\n",
    "    audio = whisperx.load_audio(audio_file)\n",
    "    result = model.transcribe(audio, batch_size = batch_size,language = language)\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    model_a, metadata = whisperx.load_align_model(language_code = result[\"language\"], device = device)\n",
    "    result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments = CONFIG_DICT[\"BOOLEAN\"][0])\n",
    "\n",
    "    del model_a\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return result "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a13cbd-eb9b-4325-b725-96472b6bd208",
   "metadata": {},
   "source": [
    "## MODEL LOADING AND PREPROCESSING THE GENERATED DATA  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd9be727-011e-420f-845a-8ef15dcfb130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_subtitle(video_file, font_size):\n",
    "    if len(font_size) == 0:\n",
    "        font_size = CONFIG_DICT[\"FONT_SIZE\"]\n",
    "    else:\n",
    "        font_size = eval(font_size)\n",
    "    url = video_file\n",
    "    print(f\"url {url}\")\n",
    "    output_path = CONFIG_DICT[\"SUBTITLE_VIDEO_PATH\"]\n",
    "    ttf_file_arr = glob.glob('./ttf_file/*')\n",
    "    index = random.randint(0, len(ttf_file_arr)-1)\n",
    "    font_ttf_path = ttf_file_arr[index]\n",
    "    video = VideoFileClip(url)\n",
    "    video_w, video_h = video.size\n",
    "    audio_file = CONFIG_DICT[\"AUDIOFILEPATH\"]\n",
    "    sp.call(f\"rm -rf {audio_file}\", shell = True)\n",
    "    \n",
    "    audio = video.audio\n",
    "    audio.write_audiofile(audio_file)\n",
    "    \n",
    "    # download_audio(url, audio_file)\n",
    "    \n",
    "    TITLE = \"W\"\n",
    "    width_of_chr, height_of_chr, total_chr_one_line = find_total_character_one_frame(TITLE, font_size, font_ttf_path, video_w)\n",
    "    result = load_model(audio_file)\n",
    "    segments = result[\"segments\"]\n",
    "    new_start_time_arr, new_end_time_arr, new_word_arr = preprocess_the_generated_data(segments, total_chr_one_line)\n",
    "    \n",
    "    clip_arr, highlight_clip_arr, color_clip_arr = sentence_formation(new_word_arr, new_start_time_arr, new_end_time_arr, total_chr_one_line, video,width_of_chr,\n",
    "                                                      height_of_chr, font_ttf_path)\n",
    "    \n",
    "    EFFECTS_ARR = CONFIG_DICT[\"EFFECTS_ARR\"]\n",
    "    EFFECTS = random.choice(EFFECTS_ARR)\n",
    "    \n",
    "    if EFFECTS == \"color_clip\":\n",
    "        final_clip = CompositeVideoClip([video, *color_clip_arr, *clip_arr])\n",
    "    elif EFFECTS == \"highlight_clip\":\n",
    "        final_clip = CompositeVideoClip([video, *clip_arr, *highlight_clip_arr])\n",
    "    else:\n",
    "        final_clip = CompositeVideoClip([video, *color_clip_arr, *clip_arr, *highlight_clip_arr])\n",
    "    \n",
    "    final_clip.write_videofile(output_path)\n",
    "    \n",
    "    return output_path\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a73e3d-ec70-4771-b8cd-d7aaba56b351",
   "metadata": {},
   "source": [
    "# Gradio Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87de0ba-7d6f-4f98-aabd-50b00bb59cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://c81a6a8fe6c607e28c.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c81a6a8fe6c607e28c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # Subtitle Video Generation\n",
    "        \n",
    "        \"\"\"\n",
    "    )\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            with gr.Row():\n",
    "                font_size = gr.Text(label = \"Font Size\", lines = 2, interactive=True)\n",
    "            with gr.Row():\n",
    "                input_video = gr.Video(show_label = \"Upload your video file here\", interactive = True, sources = \"upload\")\n",
    "            with gr.Row():\n",
    "                submit = gr.Button(\"Upload\")\n",
    "        with gr.Column():\n",
    "            file_output = gr.Video(label = \"Subtitle video(mp4)\")\n",
    "        \n",
    "    submit.click(add_subtitle, inputs = [input_video, font_size], outputs = file_output)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.queue(max_size = 10)\n",
    "    demo.launch(share = True,debug = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8faef8-225f-4650-8dc1-16ce34a04172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "whisperx",
   "name": "pytorch-gpu.2-0.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m112"
  },
  "kernelspec": {
   "display_name": "whisper_x",
   "language": "python",
   "name": "whisperx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
